---
title: "R Notebook"
output: html_notebook
---
###Using the publicly available Depmap and CCLE data to identify the potential predictive biomarkers for PPARG dependency

###Using glmnet (elastic net or lasso based methods to build model and also select features)

###Using interpretable ML to understand the feature importance and obtain global/local model interpretation

```{r}
dir()
```


```{r}
pparg_associations <- read.csv("PPARG in Avana associations.csv")
pparg_associations[1:3,]
```

```{r}
unique(pparg_associations$Dataset)
```



```{r}
ccle_expr <- read.csv("CCLE_expression (2).csv")
ccle_expr[1:2,1:5]
```



```{r}
achilles <- read.csv("Achilles_gene_effect (2).csv")
achilles[1:3,1:5]
```


```{r}
row.names(ccle_expr) <- ccle_expr$X
row.names(achilles) <- achilles$X
```

```{r}
#install.packages("DescTools")
```

```{r}
library(DescTools)
```

```{r}
expr_genes <- pparg_associations[pparg_associations$Dataset=="Expression DepMap Consortium 20Q4",]$Gene.Compound
crispr_genes <- pparg_associations[pparg_associations$Dataset=="CRISPR (Avana) DepMap Consortium 20Q4",]$Gene.Compound 
```

```{r}
crispr_genes
```



```{r}
expr_genes
```

```{r}
expr_pattern <- paste0(expr_genes,"\\..%")
expr_pattern
```


```{r}
colnames(ccle_expr)[colnames(ccle_expr) %like any% c("CDH1\\..%")]
```


```{r}
expr_genes_matched<- colnames(ccle_expr)[colnames(ccle_expr) %like any% expr_pattern]
expr_genes_matched
```

##the PPARG crisper dependency score
```{r}
colnames(achilles)[colnames(achilles) %like any% c("PPARG\\..%")]
```

```{r}
length(achilles$PPARG..5468.)
```

```{r}
shared_cell_lines <- intersect(achilles[!is.na(achilles$PPARG..5468.),]$X,ccle_expr$X)
length(shared_cell_lines)
```
```{r}
#install.packages("glmnet")
```





```{r}
require(RCurl); 
require(caret);
library(data.table)    # provides enhanced data.frame
library(ggplot2)       # plotting
library(glmnet)        # ridge, elastic net, and lasso 
```





```{r,fig.height=6,fig.width=4}
#  glmnet requires x matrix (of predictors) and vector (values for y)
y = achilles[shared_cell_lines,]$PPARG..5468.                      # vector y values
#x = model.matrix(y~.,ccle_expr[shared_cell_lines,expr_genes_matched])       # matrix of predictors
x=as.matrix(ccle_expr[shared_cell_lines,expr_genes_matched])

set.seed(123)                                # replicate  results
en_model <- cv.glmnet(x, y, alpha=0.5)         # 0 < alpha < 1 elastic net
best_lambda_en <- en_model$lambda.1se     # largest lambda in 1 SE
en_coef <- en_model$glmnet.fit$beta[,        # retrieve coefficients
              en_model$glmnet.fit$lambda     # at lambda.1se
              == best_lambda_en]
coef_en = data.table(elasticNet = en_coef)   # build table
coef_en[, feature := names(en_coef)]      # add feature names
to_plot_r = melt(coef_en                     # label table
               , id.vars='feature'
               , variable.name = 'model'
               , value.name = 'coefficient')
ggplot(data=to_plot_r,                       # plot coefficients
       aes(x=feature, y=coefficient, fill=model)) +
       coord_flip() +         
       geom_bar(stat='identity', fill='brown4', color='blue') +
       facet_wrap(~ model) + guides(fill=FALSE) 
```

```{r,fig.height=6,fig.width=4}
#  glmnet requires x matrix (of predictors) and vector (values for y)
y = achilles[shared_cell_lines,]$PPARG..5468.                      # vector y values
#x = model.matrix(y~.,ccle_expr[shared_cell_lines,expr_genes_matched])       # matrix of predictors
x=as.matrix(ccle_expr[shared_cell_lines,expr_genes_matched])
scaled.x=scale(x)

set.seed(123)                                # replicate  results
en_model <- cv.glmnet(scaled.x, y, alpha=0.5)         # 0 < alpha < 1 elastic net
best_lambda_en <- en_model$lambda.1se     # largest lambda in 1 SE
en_coef <- en_model$glmnet.fit$beta[,        # retrieve coefficients
              en_model$glmnet.fit$lambda     # at lambda.1se
              == best_lambda_en]
coef_en = data.table(elasticNet = en_coef)   # build table
coef_en[, feature := names(en_coef)]      # add feature names
to_plot_r = melt(coef_en                     # label table
               , id.vars='feature'
               , variable.name = 'model'
               , value.name = 'coefficient')
ggplot(data=to_plot_r,                       # plot coefficients
       aes(x=feature, y=coefficient, fill=model)) +
       coord_flip() +         
       geom_bar(stat='identity', fill='brown4', color='blue') +
       facet_wrap(~ model) + guides(fill=FALSE) 
```
###Let me try to interpret the model:
```{r}
#install.packages("iml")
```

```{r}
library(iml)
```
Using the interpretable machine learning library (iml) to illustrate the fetures;
#iml needs data frame yet glmnet need matrix format input
#there needs to be a work-around

##the following code will not work
```{r}
# #data1 <- as.data.frame(x)
# #colnames(data1) <- expr_genes_matched
# iml_predictor <- Predictor$new(en_model, data = x, y = y)  #pass the x,y values from above
# imp_features <- FeatureImp$new(iml_predictor, loss = "mse")
# library("ggplot2")
# plot(imp_features)
```

#the work around:
https://github.com/christophM/iml/issues/29

```{r}
##adapted from the github repo above
predict.function=function(object, newdata){
newData_x = data.matrix(newdata)
results<-predict(en_model, newData_x)
return(results)
}

data1 <- as.data.frame(x)
colnames(data1) <- expr_genes_matched

iml_predictor <- Predictor$new(en_model, data = data1, y = y,
                           predict.fun = predict.function)
imp_features <- FeatureImp$new(iml_predictor, loss = "mse")
plot(imp_features)
#shapley   <- Shapley$new(predictor, x.interest = x[1,], sample.size = 10, run = TRUE)
```

```{r}
imp_features
```
##Permutation-based feature importance measures
#http://uc-r.github.io/iml-pkg
##
```{r,fig.height=5,fig.width=2}
plot(imp_features)
```

```{r}
#install.packages("gower")
library(gower)
```




##interpret a single instance
```{r}
lime.explain <- LocalModel$new(iml_predictor, k=10,x.interest = data1[1, ])
```



```{r}
which(y< (-0.5))
```



###explain the 1st item
```{r}
plot(lime.explain)
```


###Let's check the most dependent cell lines (CRES score <-0.5)
##take the 26th, 209th records as examples
```{r}
lime.explain26 <- LocalModel$new(iml_predictor, k=10,x.interest = data1[26, ])
plot(lime.explain26)
```

```{r}
lime.explain209 <- LocalModel$new(iml_predictor, k=10,x.interest = data1[209, ])
plot(lime.explain209)
```


```{r}
cell_sampleinfo <- read.csv("sample_info (1).csv")
cell_sampleinfo[1:3,]
```


```{r}
row.names(cell_sampleinfo) <- cell_sampleinfo$DepMap_ID
```


```{r}
nrow(ccle_expr[shared_cell_lines,expr_genes_matched])
```

```{r}
colnames(cell_sampleinfo)
```



```{r}
k=ccle_expr[shared_cell_lines,expr_genes_matched]
k$PPARG_crispr <- achilles[shared_cell_lines,]$PPARG..5468. 
k$ID <- row.names(k)
k<- merge(k, cell_sampleinfo,by.x="ID",by.y="DepMap_ID")
```


```{r}
colnames(cell_sampleinfo)
```


```{r}
cell_sampleinfo[shared_cell_lines,c("primary_disease","")][1:2,]
```
###
### let me try to check to see which of any of the highly dependent cells lines are bladder, and which are not and see whether there is a difference for them
###
###

```{r}
cell_sampleinfo_in_the_same_order<- cell_sampleinfo[shared_cell_lines,]
```


```{r}
hist(y)
```
```{r}
index_less_than_minus_point_five <- which (y< (-0.5))
```

```{r}
sample_records_less_than_minus_point_five <- cell_sampleinfo_in_the_same_order[which (y< (-0.5)),]
```

```{r}
sample_records_less_than_minus_point_five$Index_number <- index_less_than_minus_point_five
```

```{r}
colnames(sample_records_less_than_minus_point_five)
```

```{r}
unique(sample_records_less_than_minus_point_five$primary_disease)
```
```{r}
sample_records_less_than_minus_point_five
```


```{r}
sample_records_less_than_minus_point_five[sample_records_less_than_minus_point_five$primary_disease %in% c("Pancreatic Cancer"),]$Index_number
```

```{r}
sample_records_less_than_minus_point_five[sample_records_less_than_minus_point_five$primary_disease %in% c("Bladder Cancer"),]$Index_number
```


```{r}
sample_records_less_than_minus_point_five[sample_records_less_than_minus_point_five$primary_disease %in% c("Colon/Colorectal Cancer"),]$Index_number
```
### explain bladder: 302 400 491 647 654
```{r}
lime.explain302 <- LocalModel$new(iml_predictor, k=10,x.interest = data1[302, ])
plot(lime.explain302)
```
```{r}
lime.explain400 <- LocalModel$new(iml_predictor, k=10,x.interest = data1[400, ])
plot(lime.explain400)
```

```{r}
lime.explain491 <- LocalModel$new(iml_predictor, k=10,x.interest = data1[491, ])
plot(lime.explain491)
```

```{r}
lime.explain647 <- LocalModel$new(iml_predictor, k=10,x.interest = data1[647, ])
plot(lime.explain647)
```

```{r}
lime.explain654 <- LocalModel$new(iml_predictor, k=10,x.interest = data1[654, ])
plot(lime.explain654)
```


### explain pancreatic cancer
## 26 329 361 635 637 639

```{r}
lime.explain26 <- LocalModel$new(iml_predictor, k=10,x.interest = data1[26, ])
plot(lime.explain26)
```

```{r}
lime.explain329 <- LocalModel$new(iml_predictor, k=10,x.interest = data1[329, ])
plot(lime.explain329)
```

```{r}
lime.explain361 <- LocalModel$new(iml_predictor, k=10,x.interest = data1[361, ])
plot(lime.explain361)
```

```{r}
lime.explain635 <- LocalModel$new(iml_predictor, k=10,x.interest = data1[635, ])
plot(lime.explain635)
```
```{r}
lime.explain637 <- LocalModel$new(iml_predictor, k=10,x.interest = data1[637, ])
plot(lime.explain637)
```

```{r}
lime.explain639 <- LocalModel$new(iml_predictor, k=10,x.interest = data1[639, ])
plot(lime.explain639)
```

```{r}
which(y>0.5)
```

##Another way to provide local interpretation is using SHAPLEY values
```{r,fig.height=5,fig.width=3}
##explain a bladder sample
shapley302 <- Shapley$new(iml_predictor, x.interest = data1[302, ]) 
plot(shapley302)
```

```{r,fig.height=5,fig.width=3}
##explain a pancreatic sample
shapley26 <- Shapley$new(iml_predictor, x.interest = data1[26, ]) 
plot(shapley26)
```


###The overall summary here:
##(1) the feature importance based on permutation in iml results are similar to the coeficients of the glm model, although not always the sam
##(2) The local models for the highly dependent ones are all similar to the global models in both the bladder and pancreatic cancer smaples
##(3) the local interpretation using LIME and SHAPLEY scores are similar

```{r,fig.height=4,fig.width=4}
ggplot(k) +geom_point(aes(x=PPARG..5468.,y=PPARG_crispr,size=PPARG..5468.,shape=primary_disease))
```

```{r,fig.height=4,fig.width=4}
ggplot(k) +geom_point(aes(x=PPARG..5468.,y=PPARG_crispr,size=GKN1..56287.,shape=primary_disease))
```

```{r,fig.height=4,fig.width=4}
ggplot(k) +geom_point(aes(x=PPARG..5468.,y=PPARG_crispr,size=k$PRR15..222171.,shape=primary_disease))
```

```{r,fig.height=4,fig.width=4}
ggplot(k) +geom_point(aes(x=PPARG..5468.,y=PPARG_crispr,size=AMPD2..271.,shape=primary_disease))
```

```{r,fig.height=4,fig.width=4}
ggplot(k) +geom_point(aes(x=PPARG..5468.,y=PPARG_crispr,size=FOXQ1..94234.,shape=primary_disease))
```


```{r,fig.height=4,fig.width=4}
ggplot(k) +geom_boxplot(aes(x=primary_disease,y=PPARG_crispr)) + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

```{r}
en_model
```

```{r}
plot(en_model)
```

```{r}
crispr_pattern <- paste0(crispr_genes,"\\..%")
crispr_genes_matched<- colnames(achilles)[colnames(achilles) %like any% crispr_pattern]
crispr_genes_matched
```

##to see what other depmap dependencies are correlated with PPARG dependencies
```{r,fig.height=6,fig.width=4}
#  glmnet requires x matrix (of predictors) and vector (values for y)
y = achilles[shared_cell_lines,]$PPARG..5468.                      # vector y values

x=as.matrix(achilles[shared_cell_lines,crispr_genes_matched])
scaled.x=scale(x)

set.seed(123)                                # replicate  results
en_model <- cv.glmnet(scaled.x, y, alpha=0.5)         # 0 < alpha < 1 elastic net
best_lambda_en <- en_model$lambda.1se     # largest lambda in 1 SE
en_coef <- en_model$glmnet.fit$beta[,        # retrieve coefficients
              en_model$glmnet.fit$lambda     # at lambda.1se
              == best_lambda_en]
coef_en = data.table(elasticNet = en_coef)   # build table
coef_en[, feature := names(en_coef)]      # add feature names
to_plot_r = melt(coef_en                     # label table
               , id.vars='feature'
               , variable.name = 'model'
               , value.name = 'coefficient')
ggplot(data=to_plot_r,                       # plot coefficients
       aes(x=feature, y=coefficient, fill=model)) +
       coord_flip() +         
       geom_bar(stat='identity', fill='brown4', color='blue') +
       facet_wrap(~ model) + guides(fill=FALSE) 
```


```{r}
nrow(x)
```

```{r}
plot(en_model)
```

